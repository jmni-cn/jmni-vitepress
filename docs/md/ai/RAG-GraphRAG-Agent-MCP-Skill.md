[B站合集](https://space.bilibili.com/16433002/lists/5310060?type=season)

一句话：从 **Prompt → Agent → 工具调用/协议(MCP) → RAG/GraphRAG → 提示词/上下文工程 → 终端自动化 → 推理（CoT）认知 → Skill 化沉淀**，把“让大模型真正干活”的关键拼图串起来。

* **交互层**：Prompt / Prompt Engineering / Context Engineering（怎么说、说多少、怎么组织上下文）
* **执行层**：Agent（模型↔工具↔用户的“执行器”）+ Function Calling / Tool Use 
* **解耦层**：MCP（让 Agent 和工具服务解耦、可复用的标准）
* **知识层**：RAG（向外部知识检索）→ GraphRAG（用图结构解决多跳/全局问题）
* **工程化沉淀**：Skill（把提示词 + 过程 + 资源/工具封装成可按需加载的单元）
* **认知校准**：思维链（CoT）到底在“推理”还是“编故事”，如何看待它的可靠性

---

# 逐集知识点提炼

## 1）《10分钟讲清楚 Prompt, Agent, MCP 是什么》

**核心知识点**

* Prompt 分 **User Prompt** 与 **System Prompt**：前者是问题/需求，后者是“人设/规则/偏好/背景”。
* **Agent** 是一个程序：负责在“用户 ↔ 大模型 ↔ 工具”之间传递信息并循环执行任务。
* **Function Calling** 用结构化方式描述工具与参数，降低模型输出格式错误带来的重试成本。
* **MCP**：把工具做成“可被查询/调用的服务”，让 Agent 与工具解耦、复用。

**你可以立刻做的练习**：写一个系统提示词，把“输出格式/禁忌/验收标准”固定下来，再对同一任务换不同 user prompt 观察差异。

---

## 2）《原来写一个 AI Agent 这么简单》

**核心知识点**

* “最小 Agent”= **消息循环 + 工具注册 + 工具执行 + 结果回填**。
* 让模型“看见你的能力”的关键：工具函数要**命名清晰、类型标注完整、必要时写 docstring**（模型会读）。
* 用现成框架（示例中提到 pydantic-ai / Gemini 等）可以把样板代码大幅压缩，重点放在工具与流程。

**练习**：做一个“文件管家 Agent”（list/read/rename 三个工具），让模型通过工具完成“整理目录”的任务。

---

## 3）《8分钟教会你写 MCP》

**核心知识点**

* MCP 的定位：一种连接 **Agent ↔ 工具/资源/提示词模板** 的协议/服务形态（Anthropic 开源标准）。
* 写 MCP Server 的最小步骤：

  1. 写工具函数（类型标注、清晰命名）
  2. 创建 MCP 实例
  3. 注册工具（add_tool 或装饰器）
  4. run 启动服务（选择通信模式）
* 价值：**工具与 Agent 解耦**——换 Agent 不用重写工具，换工具也不影响 Agent。

**练习**：把你在第2集写的“文件管家工具”拆出去，改成一个 MCP Server，然后让不同 Agent 去调用它。

---

## 4）《这就是RAG 一看就懂的个人知识库架构》

**核心知识点**

* RAG 的基本范式：**先检索（retrieval）再生成（generation）**，用外部知识补齐模型“知识固化/幻觉”。
* 个人知识库的关键模块：数据源 → 切分/清洗 → embedding → 向量库 → 检索器 → 生成器（拼接上下文）。
* 重要“坑”：文档结构差异大、切分可能截断指代关系；有些“沾点边但不够相关”的问题，RAG 也可能处理不好。

**练习**：拿 10 篇你的笔记做一个最小 RAG：PDF/Markdown loader → chunk → embeddings → vector store → top-k 检索 → 拼接回答。

---

## 5）《从零写AI RAG 个人知识库》

**核心知识点（更偏实战落地）**

* 你需要明确 3 个设计决策：

  * **切分策略**（按段落/标题/语义）
  * **检索策略**（向量/关键词/混合；top-k；重排）
  * **上下文拼接策略**（引用、去重、长度控制）
* 评估方式：用一组固定问题集做回归测试（能不能稳定命中证据、引用是否正确）。

---

## 6）《AI编程 Vibe Coding的原理是什么？》

**核心知识点**

* Vibe Coding：用自然语言驱动 AI 生成/修改代码，人更像“产品负责人 + 评审 + 测试”。
* 这个词在 2025 年迅速流行（Karpathy 提出并传播），本质是**把“写代码”前移成“说清楚目标 + 快速迭代验收”**。
* 实践要点（踩坑常见）：需求拆分、约束输出、自动化测试/回归、让 AI 按 diff/PR 方式提交变更（便于审）。

**练习**：挑一个小项目（脚本/小网页），用“需求→验收标准→分任务→逐步提交”流程做 3 轮迭代。

---

## 7）《AI知识图谱 GraphRAG 是怎么回事？》

**核心知识点**

* GraphRAG = RAG + 图结构：把文本抽成**实体-关系图**，用图来做多跳推理/全局概括类问题。
* 典型流程：索引构建（抽实体关系/聚类社区）→ 查询（全局搜索 vs 局部搜索）。
* 适用场景：

  * “跨文档关联/多跳链路”问题
  * “问整体脉络/全局总结”问题（传统向量 top-k 容易只召回局部）。

---

## 8）《AI 提示词工程 上下文工程 15分钟弄懂！》

**核心知识点**

* Prompt Engineering：把指令写清楚（角色、目标、输出格式、约束、示例）。
* Context Engineering：更工程化地管理上下文（放哪些信息、怎么压缩、如何隔离干扰、如何“长期记忆化”）。
* 常用招式：System + User 的分层、结构化输出、用示例约束行为、对“思维链/解释”保持审慎。

---

## 9）《一段提示词 让Gemini CLI变成自动化Agent！》

**核心知识点**

* 把 Prompt **封装成命令**：通过文件/命令名管理，让 CLI 接受参数（args 占位符），形成可复用“工作流命令”。
* 用“过程文件”（例如 progress.md）让 AI **持续写入状态**，从而实现更可控的自动化流程。
* 本质：提示词 + 上下文管理 + 工具调用，把“单次对话”升级成“可运行的自动化任务”。

**练习**：做一个 `translate_url` 命令：输入网址 → 下载 → 抽取正文/图片 → 输出中英双语版本（并记录进度）。

---

## 10）《AI思维链是幻象吗？ [白话读论文]》

**核心知识点**

* CoT 提示能显著提升复杂推理任务表现（经典结论）。
* 但“看起来像推理”的文字不一定等于“真的在推理”：有研究用**置信度轨迹**等方式去区分“探索式推理” vs “事后编理由”。
* 实务建议：把 CoT 当作**帮助模型算对/做对**的手段，而不是可直接信任的“真实思考过程”。

---

## 11）《什么是大模型Skill 10分钟弄懂》

**核心知识点**

* Skill：**结构化的提示词管理与执行机制**，不仅存指令，还封装领域知识、操作逻辑与工具，并支持按需加载。
* 解决的问题：提示词越多越乱（token 成本/上下文干扰/记忆负担）；Skill 用“模块化”解决可复用与可维护。
* 典型形态：以文件夹组织，核心文件（如 skill.md）+ 资源/模板/工具说明。

**练习**：把你第9集的“翻译工作流提示词”做成一个 Skill：固定输入输出规范、失败重试策略、产物目录结构。

---

# 一条“照着做就能产出作品”的学习路径

- 1 → 2 → 3：先把 Prompt/Agent/MCP 跑通（能调用工具完成任务）
- 4 → 5：再做一个最小 RAG 个人知识库（能从文档回答并引用证据）
- 8 → 9：用上下文工程把它变成“终端自动化 Agent”（命令化/流程化）
- 7：遇到“多跳/全局”问题再上 GraphRAG（别一开始就复杂化）
- 10 → 11：最后做“可靠性认知 + Skill 化沉淀”，让系统可长期维护

